{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoreNLP Parsing with NLTK Wrapper\n",
    "\n",
    "<br>\n",
    "This utilizes the NLTK Wrapper for CoreNLP in order to parse sentences from BBN/ACCENT to identify additionally verbs to add to PETRARCH Dictionaries to increase precision and Recall\n",
    "<br>\n",
    "<br>\n",
    "Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPServer\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "from nltk.parse import CoreNLPParser\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "import nltk\n",
    "\n",
    "from nltk.tree import *\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server Terminal > cd / > cd $CORENLP_HOME\n",
    "<br>\n",
    "java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators \"tokenize,ssplit,pos,lemma,parse,sentiment\" -port 9000 -timeout 30000\n",
    "<br>\n",
    "<br>\n",
    "Connect parser to server running CoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CoreNLPParser('http://localhost:9000')\n",
    "depr = CoreNLPDependencyParser('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYTBatch50 Accent\n",
    "#### Read in NYTbatch50 BBN/ACCENT DATA, trim to CAMEO 145, and create a subset of events to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>aid</th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240</td>\n",
       "      <td>22338793</td>\n",
       "      <td>145</td>\n",
       "      <td>\\n     Yesterday the news agency reported that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241</td>\n",
       "      <td>22339503</td>\n",
       "      <td>145</td>\n",
       "      <td>\"Thirty-four men arrested late last night were...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242</td>\n",
       "      <td>22395783</td>\n",
       "      <td>145</td>\n",
       "      <td>\"In the worst outbreak of street violence in 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>22398252</td>\n",
       "      <td>145</td>\n",
       "      <td>Paris policemen and leftist extremists clash a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>244</td>\n",
       "      <td>22407123</td>\n",
       "      <td>145</td>\n",
       "      <td>Violence occurred through most of the day, des...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       aid  code                                               text  \\\n",
       "0    240  22338793   145  \\n     Yesterday the news agency reported that...   \n",
       "1    241  22339503   145  \"Thirty-four men arrested late last night were...   \n",
       "2    242  22395783   145  \"In the worst outbreak of street violence in 1...   \n",
       "3    243  22398252   145  Paris policemen and leftist extremists clash a...   \n",
       "4    244  22407123   145  Violence occurred through most of the day, des...   \n",
       "\n",
       "   bad  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract = pd.read_csv('nytextract.csv')\n",
    "protest_violent = extract[extract.code == 145].reset_index()\n",
    "small = protest_violent.head()\n",
    "small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create regular sentence parser: input data and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_parser(df, col):\n",
    "    parse = []\n",
    "    i = \"\"\n",
    "    for i in range(len(df)):\n",
    "        parse.append(i)\n",
    "        parse[i] = next(parser.raw_parse(df[col].iloc[i]))\n",
    "    return parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run core_parser with small batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time nyt = core_parser(protest_violent, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To view each parse-tree, index result of function starting at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dependency sentence parser: input data and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parser(df, col):\n",
    "    dep = []\n",
    "    i = \"\"\n",
    "    for i in range(len(df)):\n",
    "        dep.append(i)\n",
    "        dep[i] = next(depr.raw_parse(df[col].iloc[i]))\n",
    "    return dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(parser.raw_parse(\"Israel said a mortar bomb was launched at it from the Gaza strip on Tuesday\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run dep_parser with small batch test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time nyt_dep = dep_parser(protest_violent, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To view each dependency parse-tree, index result of function starting at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_dep[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To view both trees simultaneously, use function 'easy_read' with three arguments (corpus 1, corpus 2, and index number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_read(parse, dep, corp, index_num, text_col_name):\n",
    "    display(parse[index_num])\n",
    "    display(dep[index_num])\n",
    "    display(corp.iloc[index_num].loc[text_col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_read(nyt, nyt_dep, protest_violent, 24, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protest_violent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYTbd Sample 14-18\n",
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1418 = pd.read_csv(\"ACCENT NYTbd sample 14 18.csv\")\n",
    "%time bd1418 = core_parser(sample1418, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time bd1418_dep = dep_parser(sample1418, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_read(bd1418, bd1418_dep, sample1418, 0, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1418"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraneous Projects\n",
    "#### py-CoreNLP Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "def depparse(text):\n",
    "    parsed=\"\"\n",
    "    output = nlp.annotate(text, properties={\n",
    "      'annotators': 'depparse',\n",
    "      'outputFormat': 'json'\n",
    "      })\n",
    "\n",
    "    for i in output[\"sentences\"]:\n",
    "        for j in i[\"basicDependencies\"]:\n",
    "            parsed=parsed+str(j[\"dep\"]+'('+ j[\"governorGloss\"]+' ')+str(j[\"dependentGloss\"]+')'+' ')\n",
    "        return parsed\n",
    "text=\"I put the book in the box on the table.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stanford NLP Python Package Parser\n",
    "The sentence structure of the BBN/ACCENT output makes it impossible to loop through... going to need to do some REGEX work on it to get it into a format where sentences are not broken up. Assuming 'nlp' command breaks up sentences at any '.' which is going to be a problem when trying to clean it up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import stanfordnlp\n",
    "stanfordnlp.download('en')   # This downloads the English models for the neural pipeline\n",
    "nlp = stanfordnlp.Pipeline() # This sets up a default neural pipeline in English\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")\n",
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanlp(df, col):\n",
    "    for i in range(len(df)):\n",
    "        arg = nlp(df[col].iloc[i])\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flop = stanlp(protest_violent, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flop.sentences[1].print_dependencies()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
